{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AndresMontesDeOca/Redes_Neuronales/blob/main/06_Redes_Neuronales_Conv.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Libraries and Data Load"
      ],
      "metadata": {
        "id": "_r_jljmGV25F"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "HIP8SbdLIkDZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "572859fb-14de-4fd6-feab-6e0d3191d40e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import random\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import InputLayer, Dense, Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler, MinMaxScaler\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
        "from tensorflow.keras.preprocessing.image import NumpyArrayIterator\n",
        "\n",
        "\n",
        "ColabNotebook = 'google.colab' in str(get_ipython())\n",
        "\n",
        "if ColabNotebook:\n",
        "    # monta G-drive en entorno COLAB\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive/')\n",
        "\n",
        "    # carpeta donde se encuentran archivos .py auxiliares\n",
        "    FUENTES_DIR = '/content/drive/MyDrive/Colab Notebooks/Redes_Neuronales/Fuentes/'\n",
        "    DATOS_DIR = '/content/drive/MyDrive/Colab Notebooks/Redes_Neuronales/Data/'      # carpeta donde se encuentran los datasets\n",
        "else:\n",
        "    # configuración para notebook con instalación LOCAL\n",
        "    FUENTES_DIR = '../Fuentes'         # carpeta donde se encuentran archivos .py auxiliares\n",
        "    DATOS_DIR   = '../Datos/' # carpeta donde se encuentran los datasets\n",
        "\n",
        "# agrega ruta de busqueda donde tenemos archivos .py\n",
        "import sys\n",
        "sys.path.append(FUENTES_DIR)\n",
        "\n",
        "################################################################\n",
        "def plot_history(history, start_epoch=0, metrics=None):\n",
        "    if isinstance(metrics, str):\n",
        "        metrics = [metrics]\n",
        "\n",
        "    if metrics is None:\n",
        "        metrics = [x for x in history.history.keys() if x[:4] != 'val_']\n",
        "\n",
        "    if len(metrics) == 0:\n",
        "        print('No metrics to display.')\n",
        "        return\n",
        "\n",
        "    # Get the epochs and filter them starting from start_epoch\n",
        "    x = history.epoch[start_epoch:]\n",
        "\n",
        "    rows = 1\n",
        "    cols = len(metrics)\n",
        "    count = 0\n",
        "\n",
        "    plt.figure(figsize=(12 * cols, 8))\n",
        "\n",
        "    for metric in sorted(metrics):\n",
        "        count += 1\n",
        "        plt.subplot(rows, cols, count)\n",
        "        plt.plot(x, history.history[metric][start_epoch:], label='Train')\n",
        "        val_metric = f'val_{metric}'\n",
        "        if val_metric in history.history.keys():\n",
        "            plt.plot(x, history.history[val_metric][start_epoch:], label='Validation')\n",
        "        plt.title(metric.capitalize())\n",
        "        plt.legend()\n",
        "    plt.show()\n",
        "################################################################"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 01 - Ejercicio MINST"
      ],
      "metadata": {
        "id": "RSY0txOa7N8L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import time\n",
        "# import numpy as np\n",
        "# from sklearn.model_selection import train_test_split\n",
        "# from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
        "# from tensorflow.keras.models import Sequential\n",
        "# from tensorflow.keras.layers import Dense\n",
        "# from tensorflow.keras.regularizers import l1, l2\n",
        "\n",
        "# from tensorflow.keras.datasets import mnist\n",
        "# (X_train, Y_train), (X_test, Y_test) = mnist.load_data()\n",
        "\n",
        "# # Redimensionar los datos para que sean compatibles con MinMaxScaler\n",
        "# X_train = X_train.reshape(-1, 28 * 28)\n",
        "# X_test = X_test.reshape(-1, 28 * 28)\n",
        "\n",
        "# # 2. Normalizar los valores de las imágenes a un rango de 0 a 1 utilizando MinMaxScaler\n",
        "# scaler = MinMaxScaler()\n",
        "# X_train = scaler.fit_transform(X_train)\n",
        "# X_test = scaler.transform(X_test)\n",
        "\n",
        "# # Volver a dar forma a los datos para que sean compatibles con la entrada de Conv2D\n",
        "# X_train = X_train.reshape(-1, 28, 28, 1)\n",
        "# X_test = X_test.reshape(-1, 28, 28, 1)\n",
        "\n",
        "# # Convertir las etiquetas a one-hot encoding\n",
        "# Y_train = to_categorical(Y_train, 10)\n",
        "# Y_test = to_categorical(Y_test, 10)\n",
        "\n",
        "# # 3. Construir el modelo CNN\n",
        "# model = Sequential([\n",
        "#     Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
        "#     MaxPooling2D(pool_size=(2, 2)),\n",
        "#     Conv2D(64, kernel_size=(3, 3), activation='relu'),\n",
        "#     MaxPooling2D(pool_size=(2, 2)),\n",
        "#     Flatten(),\n",
        "#     Dense(64, activation='relu'),\n",
        "#     Dense(10, activation='softmax')\n",
        "# ])\n",
        "\n",
        "# patience = 5\n",
        "\n",
        "# # Compilar el modelo\n",
        "# model.compile(\n",
        "#     optimizer='adam',\n",
        "#     loss='categorical_crossentropy',\n",
        "#     metrics=['accuracy'])\n",
        "\n",
        "# early_stop = EarlyStopping(\n",
        "#     monitor='val_loss',\n",
        "#     patience=patience,\n",
        "#     restore_best_weights=True)\n",
        "\n",
        "\n",
        "\n",
        "# # 4. Entrenar el modelo\n",
        "# model.fit(\n",
        "#     X_train,\n",
        "#     Y_train,\n",
        "#     validation_data=(X_test, Y_test),\n",
        "#     epochs=10,\n",
        "#     callbacks=[early_stop],\n",
        "#     verbose=1,\n",
        "#     batch_size=200)\n",
        "\n",
        "# plot_history(model.history)\n",
        "# # 5. Guardar el modelo\n",
        "# model.save('mnist_cnn_model.h5')\n",
        "\n",
        "# print(\"Modelo entrenado y guardado como 'mnist_cnn_model.h5'\")\n",
        "\n",
        "# # model.evaluate(X_test, Y_test)"
      ],
      "metadata": {
        "id": "dhx9hMtS67vP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Evaluar el modelo en el conjunto de prueba\n",
        "# loss, accuracy = model.evaluate(X_test, Y_test, verbose=1)\n",
        "\n",
        "# print(f\"Pérdida en el conjunto de prueba: {loss:.4f}\")\n",
        "# print(f\"Precisión en el conjunto de prueba: {accuracy:.4f}\")"
      ],
      "metadata": {
        "id": "NO87-_J_MfSL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 03 Fingers"
      ],
      "metadata": {
        "id": "b_XMh6pPRnT7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Auxiliary Functions"
      ],
      "metadata": {
        "id": "85GKz9lvU2zz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#############################################################################\n",
        "def get_data(url, carpeta_destino):\n",
        "    \"\"\"\n",
        "    Descarga y extrae un archivo ZIP desde una URL a una carpeta de destino.\n",
        "\n",
        "    Parámetros:\n",
        "    url (str): La URL del archivo ZIP a descargar.\n",
        "    carpeta_destino (str): La ruta de la carpeta donde se guardará y extraerá el archivo ZIP.\n",
        "\n",
        "    Devuelve:\n",
        "    str: La ruta del directorio donde se extrajo el contenido del archivo ZIP.\n",
        "    \"\"\"\n",
        "    # Crear la carpeta de destino si no existe\n",
        "    os.makedirs(carpeta_destino, exist_ok=True)\n",
        "\n",
        "    # Descargar el archivo ZIP\n",
        "    response = requests.get(url)\n",
        "    zip_path = os.path.join(carpeta_destino, os.path.basename(url))\n",
        "\n",
        "    # Guardar el archivo ZIP descargado\n",
        "    with open(zip_path, 'wb') as f:\n",
        "        f.write(response.content)\n",
        "\n",
        "    # Extraer el contenido del archivo ZIP\n",
        "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "        zip_ref.extractall(carpeta_destino)\n",
        "\n",
        "        # Obtener el nombre del directorio extraído\n",
        "        extracted_items = zip_ref.namelist()\n",
        "        common_prefix = os.path.commonprefix(extracted_items)\n",
        "\n",
        "        # Si el common_prefix es una subcarpeta, aseguramos obtener solo el primer nivel\n",
        "        if not os.path.isdir(os.path.join(carpeta_destino, common_prefix)):\n",
        "            common_prefix = common_prefix.split('/')[0]\n",
        "\n",
        "        extracted_dir_path = os.path.join(carpeta_destino, common_prefix)\n",
        "\n",
        "    # Normalizar la ruta para asegurar compatibilidad con Windows\n",
        "    extracted_dir_path = os.path.normpath(extracted_dir_path)\n",
        "\n",
        "    # Eliminar el archivo ZIP descargado (opcional)\n",
        "    # os.remove(zip_path)\n",
        "\n",
        "    # Devolver el path donde se extrajo el ZIP\n",
        "    return extracted_dir_path\n",
        "#############################################################################\n",
        "\n",
        "#############################################################################\n",
        "def show_images_random(carpeta_raiz,  num_imagenes=1, subcarpeta='train'):\n",
        "    \"\"\"\n",
        "    Muestra un número específico de imágenes al azar de una estructura de carpetas especificada, junto con sus dimensiones.\n",
        "\n",
        "    Args:\n",
        "        carpeta_raiz (str): Ruta a la carpeta raíz que contiene las subcarpetas de imágenes.\n",
        "        subcarpeta (str): Nombre de la subcarpeta dentro de la carpeta raíz donde se encuentran las imágenes.\n",
        "                          Por defecto es 'train'.\n",
        "        num_imagenes (int): Número de imágenes a mostrar por subcarpeta. Por defecto es 1.\n",
        "\n",
        "    Raises:\n",
        "        ValueError: Si la carpeta especificada no existe.\n",
        "\n",
        "    Returns:\n",
        "        None\n",
        "\n",
        "    Example:\n",
        "        show_images_random('/ruta/a/dataset', 'train', 3)\n",
        "    \"\"\"\n",
        "    # Construir la ruta completa a la subcarpeta 'train'\n",
        "    carpeta = os.path.join(carpeta_raiz, subcarpeta)\n",
        "\n",
        "    # Verificar si la carpeta existe\n",
        "    if not os.path.isdir(carpeta):\n",
        "        raise ValueError(f\"La carpeta '{carpeta}' no existe.\")\n",
        "\n",
        "    # Obtener una lista de todas las subcarpetas en 'train'\n",
        "    subcarpetas = [d for d in os.listdir(carpeta) if os.path.isdir(os.path.join(carpeta, d))]\n",
        "\n",
        "    dimensiones = []\n",
        "\n",
        "    for subcarpeta in subcarpetas:\n",
        "        ruta_subcarpeta = os.path.join(carpeta, subcarpeta)\n",
        "\n",
        "        # Obtener una lista de todos los archivos en la subcarpeta\n",
        "        archivos = [f for f in os.listdir(ruta_subcarpeta) if os.path.isfile(os.path.join(ruta_subcarpeta, f))]\n",
        "\n",
        "        # Filtrar solo las imágenes (asumiendo formatos comunes)\n",
        "        imagenes = [f for f in archivos if f.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp', '.gif', '.tiff'))]\n",
        "\n",
        "        # Verificar si hay imágenes en la subcarpeta\n",
        "        if not imagenes:\n",
        "            print(f\"No hay imágenes en la subcarpeta '{ruta_subcarpeta}'\")\n",
        "            continue\n",
        "\n",
        "        # Seleccionar las imágenes al azar\n",
        "        imagenes_seleccionadas = random.sample(imagenes, min(num_imagenes, len(imagenes)))\n",
        "\n",
        "        for imagen_seleccionada in imagenes_seleccionadas:\n",
        "            # Abrir la imagen y obtener sus dimensiones\n",
        "            ruta_imagen = os.path.join(ruta_subcarpeta, imagen_seleccionada)\n",
        "            with Image.open(ruta_imagen) as img:\n",
        "                ancho, alto = img.size\n",
        "                profundidad = img.mode\n",
        "                dimensiones.append((imagen_seleccionada, subcarpeta, alto, ancho, profundidad, ruta_imagen))\n",
        "\n",
        "    # Mostrar las imágenes y sus dimensiones\n",
        "    if dimensiones:  # Check if any images were found\n",
        "      fig, axs = plt.subplots(1, len(dimensiones), figsize=(15, 5))\n",
        "    else:\n",
        "      print(\"No se encontraron imágenes en la carpeta especificada.\")\n",
        "\n",
        "    if len(dimensiones) == 1:\n",
        "      fig, axs = plt.subplots() # Create a single subplot\n",
        "      axs = [axs]\n",
        "    else:\n",
        "      fig, axs = plt.subplots(1, num_imagenes, figsize=(20, 5)) # Create multiple subplots\n",
        "\n",
        "    for ax, (nombre_imagen, nombre_carpeta, alto, ancho, profundidad, ruta_imagen) in zip(axs, dimensiones):\n",
        "        img = Image.open(ruta_imagen)\n",
        "        ax.imshow(img)\n",
        "        ax.set_title(f\"Archivo: {nombre_imagen}\\nCarpeta: {nombre_carpeta}\\nAlto: {alto}, Ancho: {ancho}, Profundidad: {profundidad}\")\n",
        "        ax.axis('off')\n",
        "\n",
        "    plt.show()\n",
        "#############################################################################\n",
        "def count_files_in_subfolders(path):\n",
        "    file_counts = {}\n",
        "\n",
        "    for root, dirs, files in os.walk(path):\n",
        "        for subdir in dirs:\n",
        "            subdir_path = os.path.join(root, subdir)\n",
        "            file_count = sum([len(files) for r, d, files in os.walk(subdir_path)])\n",
        "            file_counts[subdir_path] = file_count\n",
        "\n",
        "    return file_counts\n",
        "#############################################################################\n",
        "#############################################################################\n",
        "def split_datapath(base_path, val_percentage):\n",
        "    \"\"\"\n",
        "    Divide un conjunto de datos en conjuntos de entrenamiento y validación.\n",
        "\n",
        "    Args:\n",
        "        base_path (str): Ruta a la carpeta base que contiene las subcarpetas de clases.\n",
        "        val_percentage (float): Porcentaje de imágenes que se deben mover a la carpeta de validación.\n",
        "\n",
        "    Returns:\n",
        "        None\n",
        "    \"\"\"\n",
        "    classes = [d for d in os.listdir(base_path) if os.path.isdir(os.path.join(base_path, d))]\n",
        "    train_path = os.path.join(base_path, 'train')\n",
        "    val_path = os.path.join(base_path, 'validation')\n",
        "\n",
        "    os.makedirs(train_path, exist_ok=True)\n",
        "    os.makedirs(val_path, exist_ok=True)\n",
        "\n",
        "    for cls in classes:\n",
        "        class_path = os.path.join(base_path, cls)\n",
        "        if not os.path.isdir(class_path):\n",
        "            continue\n",
        "\n",
        "        images = os.listdir(class_path)\n",
        "        random.shuffle(images)\n",
        "        split_idx = int(len(images) * (1 - val_percentage))\n",
        "\n",
        "        train_images = images[:split_idx]\n",
        "        val_images = images[split_idx:]\n",
        "\n",
        "        train_class_path = os.path.join(train_path, cls)\n",
        "        val_class_path = os.path.join(val_path, cls)\n",
        "\n",
        "        os.makedirs(train_class_path, exist_ok=True)\n",
        "        os.makedirs(val_class_path, exist_ok=True)\n",
        "\n",
        "        for img in train_images:\n",
        "            shutil.move(os.path.join(class_path, img), os.path.join(train_class_path, img))\n",
        "\n",
        "        for img in val_images:\n",
        "            shutil.move(os.path.join(class_path, img), os.path.join(val_class_path, img))\n",
        "\n",
        "        # Eliminar la carpeta de clase original si está vacía\n",
        "        if not os.listdir(class_path):\n",
        "            os.rmdir(class_path)\n",
        "\n",
        "    print(\"División del conjunto de datos completada.\")\n",
        "#############################################################################"
      ],
      "metadata": {
        "id": "eis77FllTcZz"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def verificar_normalizacion(data_directory, data_type, image_size, sample_size=5):\n",
        "    # Tomar una muestra de imágenes para verificar si ya están normalizadas\n",
        "    sample_images = []\n",
        "    for root, _, files in os.walk(f'{data_directory}/{data_type}'):\n",
        "        for file in files:\n",
        "            if file.endswith(('jpg', 'jpeg', 'png')):\n",
        "                img_path = os.path.join(root, file)\n",
        "                img = load_img(img_path, target_size=image_size)\n",
        "                img_array = img_to_array(img)\n",
        "                sample_images.append(img_array)\n",
        "                if len(sample_images) >= sample_size:\n",
        "                    break\n",
        "        if len(sample_images) >= sample_size:\n",
        "            break\n",
        "    sample_images = np.array(sample_images)\n",
        "\n",
        "    # Verificar si los valores están en el rango [0, 1]\n",
        "    if sample_images.max() <= 1.0 and sample_images.min() >= 0.0:\n",
        "        return False  # Los datos ya están normalizados\n",
        "    return True  # Los datos no están normalizados\n",
        "#############################################################################\n",
        "\n",
        "#############################################################################\n",
        "def wrangle_data(data_directory, split, encoding, image_size, batch_size=32):\n",
        "    if verificar_normalizacion(data_directory, split, image_size):\n",
        "        scale_factor = 1 / 255.0\n",
        "        print('Necesita normalizacion, verificar Wrangle Data')\n",
        "    else:\n",
        "        scale_factor = None\n",
        "        print('No necesita normalizacion, verificar Wrangle Data')\n",
        "\n",
        "\n",
        "    train_datagen = ImageDataGenerator(\n",
        "        rescale=scale_factor, # Ojo!!!! nunca olvidarse\n",
        "        horizontal_flip=True,\n",
        "        # vertical_flip=True,\n",
        "        zoom_range=0.2,\n",
        "        rotation_range=30,\n",
        "        # width_shift_range=0.2,\n",
        "        # height_shift_range=0.2,\n",
        "        # brightness_range=[0.8, 1.2],\n",
        "        # shear_range=0.2,\n",
        "        fill_mode='nearest'\n",
        "    )\n",
        "\n",
        "    validation_test_datagen = ImageDataGenerator(rescale=scale_factor)\n",
        "\n",
        "    if split == 'train':\n",
        "        datagen = train_datagen\n",
        "        shuffle = True\n",
        "    elif split in ['validation', 'test']:\n",
        "        datagen = validation_test_datagen\n",
        "        shuffle = False\n",
        "    else:\n",
        "        raise ValueError(\"data_type must be one of ['train', 'validation', 'test']\")\n",
        "\n",
        "    data_flow = datagen.flow_from_directory(\n",
        "        f'{data_directory}/{split}',\n",
        "        target_size=image_size,\n",
        "        batch_size=batch_size,\n",
        "        class_mode=encoding,\n",
        "        shuffle=shuffle\n",
        "    )\n",
        "\n",
        "    return data_flow\n",
        "#############################################################################"
      ],
      "metadata": {
        "id": "710DYOkKTe2y"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Main"
      ],
      "metadata": {
        "id": "6LeLIVqwU7wa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import zipfile\n",
        "# import os\n",
        "\n",
        "# # Descomprimir en la misma carpeta\n",
        "# with zipfile.ZipFile(os.path.join(DATOS_DIR, 'fingers.zip'), 'r') as zip_ref:\n",
        "#     zip_ref.extractall(DATOS_DIR)"
      ],
      "metadata": {
        "id": "JkAzZRsUYRQV"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "EW_g7ykMdoVr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# data_path_downloaded = DATOS_DIR + \"fingers/\"\n",
        "# show_images_random(data_path_downloaded, \"test\")"
      ],
      "metadata": {
        "id": "6FmWoCC6VVaD"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_path_downloaded"
      ],
      "metadata": {
        "id": "PL4Jp7hrfMIG",
        "outputId": "fb86c82c-cd60-4b99-ca17-a02c840f42d4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/drive/MyDrive/Colab Notebooks/Redes_Neuronales/Data/fingers/'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "batch_size = 32\n",
        "image_size = (64, 64)\n",
        "class_mode = 'sparse' # binary: Las etiquetas son enteros 0 o 1, categorical: Las etiquetas son vectores one-hot, sparse: Las etiquetas son enteros\n",
        "\n",
        "\n",
        "#########################################################################\n",
        "# Cells Pipeline\n",
        "#########################################################################\n",
        "# delete_folder_colab('../data')\n",
        "# data_path = '../data/'\n",
        "# # link= 'https://data.lhncbc.nlm.nih.gov/public/Malaria/cell_images.zip'\n",
        "# link = 'https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip'\n",
        "# data_path_downloaded = get_data(link, data_path)\n",
        "# print(data_path, '\\n', data_path_downloaded, '\\n')\n",
        "# split_datapath(data_path_downloaded, 0.1)\n",
        "# count_files_in_subfolders(data_path_downloaded)\n",
        "# show_images_random(data_path_downloaded)\n",
        "data_train_wrangled = wrangle_data(data_path_downloaded, 'train', class_mode, image_size, batch_size)\n",
        "data_valid_wrangled = wrangle_data(data_path_downloaded, 'validation', class_mode, image_size, batch_size)\n",
        "# # data_test_wrnagled = wrangle_data(data_path_downloaded, 'test', class_mode, image_size)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 406
        },
        "id": "3S_TnVpWTzPf",
        "outputId": "d7b54c97-864c-49d5-ab2a-f48183b44157"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Necesita normalizacion, verificar Wrangle Data\n",
            "Found 0 images belonging to 0 classes.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "zero-size array to reduction operation maximum which has no identity",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-54-2875815055c1>\u001b[0m in \u001b[0;36m<cell line: 19>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;31m# show_images_random(data_path_downloaded)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0mdata_train_wrangled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwrangle_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_path_downloaded\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'train'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_mode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0mdata_valid_wrangled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwrangle_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_path_downloaded\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'validation'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_mode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;31m# # data_test_wrnagled = wrangle_data(data_path_downloaded, 'test', class_mode, image_size)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-21-985aa0c98306>\u001b[0m in \u001b[0;36mwrangle_data\u001b[0;34m(data_directory, split, encoding, image_size, batch_size)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;31m#############################################################################\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mwrangle_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_directory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msplit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mverificar_normalizacion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_directory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msplit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m         \u001b[0mscale_factor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m255.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Necesita normalizacion, verificar Wrangle Data'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-21-985aa0c98306>\u001b[0m in \u001b[0;36mverificar_normalizacion\u001b[0;34m(data_directory, data_type, image_size, sample_size)\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;31m# Verificar si los valores están en el rango [0, 1]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0msample_images\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m1.0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0msample_images\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m  \u001b[0;31m# Los datos ya están normalizados\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m  \u001b[0;31m# Los datos no están normalizados\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/numpy/core/_methods.py\u001b[0m in \u001b[0;36m_amax\u001b[0;34m(a, axis, out, keepdims, initial, where)\u001b[0m\n\u001b[1;32m     39\u001b[0m def _amax(a, axis=None, out=None, keepdims=False,\n\u001b[1;32m     40\u001b[0m           initial=_NoValue, where=True):\n\u001b[0;32m---> 41\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mumr_maximum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwhere\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m def _amin(a, axis=None, out=None, keepdims=False,\n",
            "\u001b[0;31mValueError\u001b[0m: zero-size array to reduction operation maximum which has no identity"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Ejercicio 4"
      ],
      "metadata": {
        "id": "b5p1_jZ_eIjv"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Qgpuq7WMeJ_a"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.16"
    },
    "varInspector": {
      "cols": {
        "lenName": "16",
        "lenType": "16",
        "lenVar": "50"
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}