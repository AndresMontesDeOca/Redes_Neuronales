{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AndresMontesDeOca/Redes_Neuronales/blob/main/Clase_04/02_Eficiencia_energetica.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vdWG2FEMDVST"
      },
      "source": [
        "# Regresion con Multiperceptrón de Scikit-Learn\n",
        "---\n",
        "**Montar la carpeta de Google Drive y definir constantes para trabajar**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "HIP8SbdLIkDZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2438ef25-99c4-4f32-8c08-1541acbd6ea3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ],
      "source": [
        "ColabNotebook = 'google.colab' in str(get_ipython())\n",
        "\n",
        "if ColabNotebook:\n",
        "    # monta G-drive en entorno COLAB\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive/')\n",
        "\n",
        "    # carpeta donde se encuentran archivos .py auxiliares\n",
        "    FUENTES_DIR = '/content/drive/MyDrive/Colab Notebooks/Redes_Neuronales/Fuentes/'\n",
        "    DATOS_DIR = '/content/drive/MyDrive/Colab Notebooks/Redes_Neuronales/Data/'      # carpeta donde se encuentran los datasets\n",
        "else:\n",
        "    # configuración para notebook con instalación LOCAL\n",
        "    FUENTES_DIR = '../Fuentes'         # carpeta donde se encuentran archivos .py auxiliares\n",
        "    DATOS_DIR   = '../Datos/' # carpeta donde se encuentran los datasets\n",
        "\n",
        "# agrega ruta de busqueda donde tenemos archivos .py\n",
        "import sys\n",
        "sys.path.append(FUENTES_DIR)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hj5GbHXwGP1j"
      },
      "source": [
        "### Carga del Dataset y selección de atributos numéricos"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ucimlrepo\n",
        "from ucimlrepo import fetch_ucirepo\n",
        "\n",
        "# fetch dataset\n",
        "energy_efficiency = fetch_ucirepo(id=242)\n",
        "\n",
        "# data (as pandas dataframes)\n",
        "X = energy_efficiency.data.features\n",
        "y = energy_efficiency.data.targets\n",
        "\n",
        "# # metadata\n",
        "# print(energy_efficiency.metadata)\n",
        "\n",
        "# # variable information\n",
        "# print(energy_efficiency.variables)\n",
        "\n",
        "data = pd.concat([X, y], axis=1)\n",
        "data.columns = energy_efficiency.variables['description'].values\n",
        "data.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X8i89cUaMnqw",
        "outputId": "02c44ea1-2923-4d22-fcd8-b3c23beb86af"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ucimlrepo\n",
            "  Downloading ucimlrepo-0.0.7-py3-none-any.whl (8.0 kB)\n",
            "Requirement already satisfied: pandas>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from ucimlrepo) (2.0.3)\n",
            "Requirement already satisfied: certifi>=2020.12.5 in /usr/local/lib/python3.10/dist-packages (from ucimlrepo) (2024.6.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.0->ucimlrepo) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.0->ucimlrepo) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.0->ucimlrepo) (2024.1)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.0->ucimlrepo) (1.25.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas>=1.0.0->ucimlrepo) (1.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "44viJuybOEYD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "outputId": "db167313-c668-432c-9067-f75b84f42f1f"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'data' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-eb25c013543c>\u001b[0m in \u001b[0;36m<cell line: 15>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m# Seleccionar características relevantes y la variable objetivo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Wall Area'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Roof Area'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Glazing Area'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Cooling Load'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'data' is not defined"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.neural_network import MLPRegressor\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "\n",
        "# # Cargar el dataset\n",
        "# DATOS_DIR = '/mnt/data/'\n",
        "# data = pd.read_csv(DATOS_DIR + 'nombre_del_archivo.csv')  # Reemplaza 'nombre_del_archivo.csv' con el nombre real del archivo\n",
        "\n",
        "# # Verificar los primeros datos\n",
        "# print(data.head())\n",
        "\n",
        "# Seleccionar características relevantes y la variable objetivo\n",
        "features = data[['Wall Area', 'Roof Area', 'Glazing Area']]\n",
        "target = data['Cooling Load']\n",
        "\n",
        "# Eliminar filas con valores faltantes\n",
        "features = features.dropna()\n",
        "target = target[features.index]\n",
        "\n",
        "# Dividir los datos en conjuntos de entrenamiento y prueba\n",
        "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=42)\n",
        "\n",
        "# Normalizar las características\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Entrenar el modelo utilizando MLPRegressor\n",
        "mlp = MLPRegressor(hidden_layer_sizes=(100,), max_iter=1000, random_state=42)\n",
        "mlp.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Realizar predicciones\n",
        "y_pred = mlp.predict(X_test_scaled)\n",
        "\n",
        "# Evaluar el modelo\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "print(f'Mean Squared Error: {mse}')\n",
        "print(f'R2 Score: {r2}')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "MAX_ITER = 10000\n",
        "COTA = 0.001\n",
        "ALFA = 0.001\n",
        "# cantidad de datos a procesar para actualizar pesos\n",
        "TAM_LOTE = 50\n",
        "\n",
        "ACTIVACION = 'relu'\n",
        "#ACTIVACION = 'tanh'\n",
        "#ACTIVATION = 'identity'\n",
        "\n",
        "#OPTIMIZADOR = 'lbfgs'\n",
        "OPTIMIZADOR = 'sgd'\n",
        "#OPTIMIZADOR = 'adam'\n",
        "\n",
        "mlpr = MLPRegressor(\n",
        "    hidden_layer_sizes=[30, 15],  # Arquitectura con tres capas ocultas\n",
        "    activation=ACTIVACION,  # Función de activación de capas ocultas.\n",
        "    solver=OPTIMIZADOR,     # Algoritmo de optimización\n",
        "    max_iter=MAX_ITER,      # Número máximo de iteraciones\n",
        "    alpha=ALFA,             # Tasa de aprendizaje.\n",
        "    random_state=None,      # Semilla para la generación de números aleatorios para reproducibilidad.\n",
        "    batch_size=TAM_LOTE,    # Tamaño del lote de datos utilizado para la actualización de pesos.\n",
        "    tol=COTA,               # Tolerancia para la convergencia de parada temprana\n",
        "    verbose=True            # Imprimir información durante el entrenamiento.\n",
        ")\n",
        "\n",
        "mlpr.fit(X_train, Y_train)\n",
        "\n",
        "print('Iteraciones realizadas: %d' % mlpr.n_iter_)"
      ],
      "metadata": {
        "id": "an9922KgPbGO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.heatmap(data.corr(),annot=True, cmap=sns.diverging_palette(20, 220, n=200), fmt='.2f')"
      ],
      "metadata": {
        "id": "YxMedUEiOf5D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bl2l7jYvG5sP"
      },
      "source": [
        "### Verificación de tipos de datos y valores nulos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ay9z2K1-9AU"
      },
      "source": [
        "### Muestra las primeras filas de los Datos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3qk1aUDu_wiB"
      },
      "source": [
        "### Matriz de Correlación con Seaborn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AKlyxpXR_9Mi"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize = (8,5))\n",
        "sns.heatmap(df.corr(),annot=True, cmap=sns.diverging_palette(20, 220, n=200), fmt='.2f')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V5Um9iFfH5i0"
      },
      "source": [
        "### Selección de atributos. Separación en entrenamiento y prueba. Normalización de valores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "If9sz9OvGrXp"
      },
      "outputs": [],
      "source": [
        "# elimina atributos redundantes\n",
        "X = np.array(df.drop(['Heating_Load','Cooling_Load', 'Relative_Compactness', 'Overall_Height'],axis=1))\n",
        "\n",
        "# Y= df[['Heating Load']]\n",
        "Y= np.array(df['Cooling_Load'])\n",
        "\n",
        "# Separa datos en grupo de entrenamiento y prueba\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.30, random_state = 20)\n",
        "\n",
        "data_scaler = StandardScaler()\n",
        "# data_scaler = MinMaxScaler()\n",
        "\n",
        "X_train = data_scaler.fit_transform(X_train)\n",
        "X_test = data_scaler.transform(X_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ufa1Z79_OMeG"
      },
      "source": [
        "### Construccion del Modelo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2VfbQNbZIgu2"
      },
      "outputs": [],
      "source": [
        "MAX_ITER = 10000\n",
        "COTA = 0.001\n",
        "ALFA = 0.001\n",
        "# cantidad de datos a procesar para actualizar pesos\n",
        "TAM_LOTE = 50\n",
        "\n",
        "ACTIVACION = 'relu'\n",
        "#ACTIVACION = 'tanh'\n",
        "#ACTIVATION = 'identity'\n",
        "\n",
        "#OPTIMIZADOR = 'lbfgs'\n",
        "OPTIMIZADOR = 'sgd'\n",
        "#OPTIMIZADOR = 'adam'\n",
        "\n",
        "mlpr = MLPRegressor(\n",
        "    hidden_layer_sizes=[30, 15],  # Arquitectura con tres capas ocultas\n",
        "    activation=ACTIVACION,  # Función de activación de capas ocultas.\n",
        "    solver=OPTIMIZADOR,     # Algoritmo de optimización\n",
        "    max_iter=MAX_ITER,      # Número máximo de iteraciones\n",
        "    alpha=ALFA,             # Tasa de aprendizaje.\n",
        "    random_state=None,      # Semilla para la generación de números aleatorios para reproducibilidad.\n",
        "    batch_size=TAM_LOTE,    # Tamaño del lote de datos utilizado para la actualización de pesos.\n",
        "    tol=COTA,               # Tolerancia para la convergencia de parada temprana\n",
        "    verbose=True            # Imprimir información durante el entrenamiento.\n",
        ")\n",
        "\n",
        "mlpr.fit(X_train, Y_train)\n",
        "\n",
        "print('Iteraciones realizadas: %d' % mlpr.n_iter_)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mlpr.out_activation_ = 'identity'"
      ],
      "metadata": {
        "id": "p3kwW88nFsVf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PmFJhBqmIykD"
      },
      "source": [
        "### Metricas sobre el modelo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YfCAbgoqIy1O"
      },
      "outputs": [],
      "source": [
        "# Realizar predicciones\n",
        "Y_pred = mlpr.predict(X_test)\n",
        "\n",
        "# Calcular métricas de evaluación usando las predicciones (Y_pred) y los valores reales (Y_test)\n",
        "mae = mean_absolute_error(Y_test, Y_pred)  # Calcular el error absoluto medio\n",
        "mse = mean_squared_error(Y_test, Y_pred)   # Calcular el error cuadrático medio\n",
        "rmse = np.sqrt(mse)                        # Calcular la raíz del error cuadrático medio\n",
        "r2 = r2_score(Y_test, Y_pred)              # Calcular el coeficiente de determinación\n",
        "\n",
        "print(f\"    Mean Absolute Error: {mae}\")\n",
        "print(f\"     Mean Squared Error: {mse}\")\n",
        "print(f\"Root Mean Squared Error: {rmse}\")\n",
        "print(f\"     R-squared r2_score: {r2}\")\n",
        "\n",
        "# tambien puede calcularse R^2 con el MLPRegressor\n",
        "print(f\" R-squared MLPRegressor:\", mlpr.score(X_test, Y_test))\n",
        "# R2 (R cuadrado) es la proporción de varianza en la variable dependiente que es predecible a\n",
        "# partir de las independientes en un modelo de regresión. R2=1 significa que el modelo explica el\n",
        "# 100% de la variabilidad en los datos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yhGLBZR_K3Pn"
      },
      "source": [
        "### Gráfico con evolución de curva de perdida"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "rX_XzvSBK2CB",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "outputId": "229c59c2-d8b3-4120-b6b9-19de562f43f2"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'mlpr' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-88072bdf906c>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mloss_curve\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmlpr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_curve_\u001b[0m  \u001b[0;31m# curva de pérdida del modelo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Dibuja curva de pérdida\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_curve\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlinewidth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'mlpr' is not defined"
          ]
        }
      ],
      "source": [
        "loss_curve = mlpr.loss_curve_  # curva de pérdida del modelo\n",
        "\n",
        "# Dibuja curva de pérdida\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(loss_curve, linewidth=2)\n",
        "plt.title('Curva de Pérdida del Modelo')\n",
        "plt.xlabel('Número de Iteraciones')\n",
        "plt.ylabel('Pérdida')\n",
        "plt.grid(True)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NaPZVmRfQoGg"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.16"
    },
    "varInspector": {
      "cols": {
        "lenName": "16",
        "lenType": "16",
        "lenVar": "50"
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}